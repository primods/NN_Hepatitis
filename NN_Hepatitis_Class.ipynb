{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NN_Hepatitis_Class.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOj4/wdWAXvvwy6MGeXd73P",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/primods/NN_Hepatitis/blob/main/NN_Hepatitis_Class.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R6zmEa3sTEE8"
      },
      "outputs": [],
      "source": [
        "#Libs for Create a Neural Network and Data Manipulation\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import Normalizer\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import ConfusionMatrixDisplay\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "#setting theme for seaborn/matplotlib plots\n",
        "sns.set()\n",
        "sns.set_palette('hls')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating Dataframe from csv data and cleaning\n",
        "\n",
        "hep_data = pd.read_csv(\"HepatitisCdata.csv\").drop(\"Unnamed: 0\", axis=1)\n",
        "y_data = hep_data[\"Category\"]\n",
        "X_data = pd.get_dummies(hep_data.drop(\"Category\", axis=1))\n",
        "\n",
        "hep_data = X_data.join(y_data)\n",
        "\n",
        "#Categorical data to numerical, dropping suspect donors (only 7 entries) and NA values\n",
        "hep_data = hep_data[hep_data[\"Category\"] != \"0s=suspect Blood Donor\"].reset_index().drop(\"index\", axis=1)\n",
        "hep_data = hep_data.replace(list(hep_data[\"Category\"].unique()),np.linspace(1,4,4))\n",
        "\n",
        "hep_data.dropna(inplace=True)\n",
        "\n",
        "\n",
        "#Replace values to make the a Binary Classification problem\n",
        "hep_data[\"Category\"] = hep_data[\"Category\"].replace([2.0,3.0,4.0],2.0)\n"
      ],
      "metadata": {
        "id": "utJyE8d2TYRT"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Option to create a balanced data set\n",
        "\n",
        "dis_df = hep_data[hep_data[\"Category\"]==2.0]\n",
        "\n",
        "#heal_df = hep_data[hep_data[\"Category\"]==1.0].sample(len(dis_df)*2)\n",
        "heal_df = hep_data[hep_data[\"Category\"]==1.0]\n",
        "\n",
        "hep_data = pd.concat([dis_df,heal_df])"
      ],
      "metadata": {
        "id": "RUeBzQgfUBR0"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting in X, y datasets and train, test sets\n",
        "\n",
        "X_values = hep_data.drop([\"Category\",\"Sex_f\",\"Sex_m\"], axis=1).values\n",
        "y_values = pd.get_dummies(hep_data[\"Category\"].values).values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_values, y_values,\n",
        "                                                    test_size=0.3, random_state=60,\n",
        "                                                    stratify=y_values)\n",
        "\n",
        "#Normalize the data\n",
        "\n",
        "X_train = Normalizer().fit_transform(X_train)\n",
        "X_test = Normalizer().transform(X_test)"
      ],
      "metadata": {
        "id": "j7fFCxXwUYMA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Create the neural network model\n",
        "\n",
        "model = keras.Sequential(\n",
        "    [keras.Input(shape=11),\n",
        "     layers.Dense(8, activation=\"relu\"),\n",
        "     layers.Dense(6, activation=\"relu\"),\n",
        "     layers.Dense(2, activation=\"sigmoid\")\n",
        "    ])"
      ],
      "metadata": {
        "id": "rSSKYyeHUc-G"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Summary of the model\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOiNaJ4jVakg",
        "outputId": "4e2e1cf8-ae2e-484d-f736-4b2db77bc584"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 8)                 96        \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 6)                 54        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 2)                 14        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 164\n",
            "Trainable params: 164\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train and fit the model witch batch size of 10 and 100 epochs\n",
        "\n",
        "batch_size = 10\n",
        "epochs = 100\n",
        "\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "\n",
        "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OFx2YfY8VekO",
        "outputId": "9f8c3fac-44e8-4953-aa72-962a80b762b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "33/33 [==============================] - 2s 26ms/step - loss: 0.7238 - accuracy: 0.2862 - val_loss: 0.6708 - val_accuracy: 0.8659\n",
            "Epoch 2/100\n",
            "33/33 [==============================] - 1s 23ms/step - loss: 0.6329 - accuracy: 0.9200 - val_loss: 0.6068 - val_accuracy: 0.8780\n",
            "Epoch 3/100\n",
            "33/33 [==============================] - 0s 15ms/step - loss: 0.5691 - accuracy: 0.9138 - val_loss: 0.5506 - val_accuracy: 0.8780\n",
            "Epoch 4/100\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.5081 - accuracy: 0.9108 - val_loss: 0.4943 - val_accuracy: 0.8780\n",
            "Epoch 5/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.4448 - accuracy: 0.9108 - val_loss: 0.4404 - val_accuracy: 0.8780\n",
            "Epoch 6/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.3855 - accuracy: 0.9108 - val_loss: 0.3976 - val_accuracy: 0.8780\n",
            "Epoch 7/100\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.3429 - accuracy: 0.9108 - val_loss: 0.3713 - val_accuracy: 0.8780\n",
            "Epoch 8/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.3142 - accuracy: 0.9108 - val_loss: 0.3564 - val_accuracy: 0.8780\n",
            "Epoch 9/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2982 - accuracy: 0.9108 - val_loss: 0.3477 - val_accuracy: 0.8780\n",
            "Epoch 10/100\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.2881 - accuracy: 0.9108 - val_loss: 0.3389 - val_accuracy: 0.8780\n",
            "Epoch 11/100\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.2783 - accuracy: 0.9108 - val_loss: 0.3252 - val_accuracy: 0.8780\n",
            "Epoch 12/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2658 - accuracy: 0.9108 - val_loss: 0.3060 - val_accuracy: 0.8780\n",
            "Epoch 13/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2521 - accuracy: 0.9108 - val_loss: 0.2833 - val_accuracy: 0.8780\n",
            "Epoch 14/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.2378 - accuracy: 0.9108 - val_loss: 0.2600 - val_accuracy: 0.8780\n",
            "Epoch 15/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.2219 - accuracy: 0.9138 - val_loss: 0.2350 - val_accuracy: 0.8780\n",
            "Epoch 16/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.2064 - accuracy: 0.9169 - val_loss: 0.2099 - val_accuracy: 0.8780\n",
            "Epoch 17/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.1894 - accuracy: 0.9169 - val_loss: 0.1857 - val_accuracy: 0.8902\n",
            "Epoch 18/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1722 - accuracy: 0.9354 - val_loss: 0.1614 - val_accuracy: 0.9268\n",
            "Epoch 19/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.1570 - accuracy: 0.9446 - val_loss: 0.1419 - val_accuracy: 0.9390\n",
            "Epoch 20/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.1442 - accuracy: 0.9446 - val_loss: 0.1273 - val_accuracy: 0.9634\n",
            "Epoch 21/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.1311 - accuracy: 0.9477 - val_loss: 0.1092 - val_accuracy: 0.9634\n",
            "Epoch 22/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.1219 - accuracy: 0.9538 - val_loss: 0.0997 - val_accuracy: 0.9634\n",
            "Epoch 23/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1156 - accuracy: 0.9600 - val_loss: 0.0886 - val_accuracy: 0.9634\n",
            "Epoch 24/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.1071 - accuracy: 0.9631 - val_loss: 0.0807 - val_accuracy: 0.9634\n",
            "Epoch 25/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9631 - val_loss: 0.0731 - val_accuracy: 0.9634\n",
            "Epoch 26/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0966 - accuracy: 0.9662 - val_loss: 0.0684 - val_accuracy: 0.9634\n",
            "Epoch 27/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0923 - accuracy: 0.9631 - val_loss: 0.0631 - val_accuracy: 0.9756\n",
            "Epoch 28/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0890 - accuracy: 0.9631 - val_loss: 0.0580 - val_accuracy: 0.9878\n",
            "Epoch 29/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0858 - accuracy: 0.9692 - val_loss: 0.0545 - val_accuracy: 1.0000\n",
            "Epoch 30/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0826 - accuracy: 0.9723 - val_loss: 0.0518 - val_accuracy: 0.9878\n",
            "Epoch 31/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0811 - accuracy: 0.9692 - val_loss: 0.0487 - val_accuracy: 1.0000\n",
            "Epoch 32/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9692 - val_loss: 0.0463 - val_accuracy: 1.0000\n",
            "Epoch 33/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0762 - accuracy: 0.9692 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
            "Epoch 34/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0744 - accuracy: 0.9692 - val_loss: 0.0423 - val_accuracy: 1.0000\n",
            "Epoch 35/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0753 - accuracy: 0.9662 - val_loss: 0.0409 - val_accuracy: 1.0000\n",
            "Epoch 36/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0715 - accuracy: 0.9692 - val_loss: 0.0384 - val_accuracy: 1.0000\n",
            "Epoch 37/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0697 - accuracy: 0.9692 - val_loss: 0.0366 - val_accuracy: 1.0000\n",
            "Epoch 38/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0681 - accuracy: 0.9723 - val_loss: 0.0353 - val_accuracy: 1.0000\n",
            "Epoch 39/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0666 - accuracy: 0.9723 - val_loss: 0.0338 - val_accuracy: 1.0000\n",
            "Epoch 40/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0654 - accuracy: 0.9723 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
            "Epoch 41/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0644 - accuracy: 0.9692 - val_loss: 0.0314 - val_accuracy: 1.0000\n",
            "Epoch 42/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0633 - accuracy: 0.9754 - val_loss: 0.0300 - val_accuracy: 1.0000\n",
            "Epoch 43/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0623 - accuracy: 0.9723 - val_loss: 0.0293 - val_accuracy: 1.0000\n",
            "Epoch 44/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0608 - accuracy: 0.9785 - val_loss: 0.0283 - val_accuracy: 1.0000\n",
            "Epoch 45/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0607 - accuracy: 0.9754 - val_loss: 0.0277 - val_accuracy: 1.0000\n",
            "Epoch 46/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0593 - accuracy: 0.9785 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
            "Epoch 47/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0588 - accuracy: 0.9785 - val_loss: 0.0259 - val_accuracy: 1.0000\n",
            "Epoch 48/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0567 - accuracy: 0.9815 - val_loss: 0.0250 - val_accuracy: 1.0000\n",
            "Epoch 49/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0565 - accuracy: 0.9785 - val_loss: 0.0241 - val_accuracy: 1.0000\n",
            "Epoch 50/100\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.0551 - accuracy: 0.9785 - val_loss: 0.0237 - val_accuracy: 1.0000\n",
            "Epoch 51/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0547 - accuracy: 0.9785 - val_loss: 0.0231 - val_accuracy: 1.0000\n",
            "Epoch 52/100\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.0529 - accuracy: 0.9785 - val_loss: 0.0225 - val_accuracy: 1.0000\n",
            "Epoch 53/100\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.0531 - accuracy: 0.9815 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
            "Epoch 54/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0517 - accuracy: 0.9815 - val_loss: 0.0218 - val_accuracy: 1.0000\n",
            "Epoch 55/100\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.0527 - accuracy: 0.9815 - val_loss: 0.0212 - val_accuracy: 1.0000\n",
            "Epoch 56/100\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.0502 - accuracy: 0.9815 - val_loss: 0.0206 - val_accuracy: 1.0000\n",
            "Epoch 57/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0493 - accuracy: 0.9815 - val_loss: 0.0203 - val_accuracy: 1.0000\n",
            "Epoch 58/100\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0484 - accuracy: 0.9815 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
            "Epoch 59/100\n",
            "33/33 [==============================] - 0s 13ms/step - loss: 0.0478 - accuracy: 0.9815 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
            "Epoch 60/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0473 - accuracy: 0.9815 - val_loss: 0.0189 - val_accuracy: 1.0000\n",
            "Epoch 61/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0474 - accuracy: 0.9815 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
            "Epoch 62/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0465 - accuracy: 0.9815 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
            "Epoch 63/100\n",
            "33/33 [==============================] - 0s 11ms/step - loss: 0.0447 - accuracy: 0.9815 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 64/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0452 - accuracy: 0.9815 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
            "Epoch 65/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0453 - accuracy: 0.9815 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
            "Epoch 66/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0437 - accuracy: 0.9815 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 67/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9815 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
            "Epoch 68/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0422 - accuracy: 0.9815 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 69/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0418 - accuracy: 0.9815 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
            "Epoch 70/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0406 - accuracy: 0.9815 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 71/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0399 - accuracy: 0.9815 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 72/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9815 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
            "Epoch 73/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0385 - accuracy: 0.9815 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 74/100\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.0387 - accuracy: 0.9815 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 75/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0379 - accuracy: 0.9877 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 76/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0376 - accuracy: 0.9846 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 77/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0368 - accuracy: 0.9846 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
            "Epoch 78/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0369 - accuracy: 0.9846 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
            "Epoch 79/100\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 0.9877 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 80/100\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.0360 - accuracy: 0.9877 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
            "Epoch 81/100\n",
            "33/33 [==============================] - 0s 8ms/step - loss: 0.0349 - accuracy: 0.9877 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 82/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0342 - accuracy: 0.9846 - val_loss: 0.0163 - val_accuracy: 1.0000\n",
            "Epoch 83/100\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.0332 - accuracy: 0.9908 - val_loss: 0.0170 - val_accuracy: 1.0000\n",
            "Epoch 84/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9908 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
            "Epoch 85/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0325 - accuracy: 0.9908 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 86/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0323 - accuracy: 0.9908 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
            "Epoch 87/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0319 - accuracy: 0.9877 - val_loss: 0.0178 - val_accuracy: 0.9878\n",
            "Epoch 88/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0316 - accuracy: 0.9908 - val_loss: 0.0171 - val_accuracy: 1.0000\n",
            "Epoch 89/100\n",
            "33/33 [==============================] - 0s 7ms/step - loss: 0.0306 - accuracy: 0.9908 - val_loss: 0.0177 - val_accuracy: 0.9878\n",
            "Epoch 90/100\n",
            "33/33 [==============================] - 0s 9ms/step - loss: 0.0306 - accuracy: 0.9877 - val_loss: 0.0180 - val_accuracy: 0.9878\n",
            "Epoch 91/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0306 - accuracy: 0.9908 - val_loss: 0.0190 - val_accuracy: 0.9878\n",
            "Epoch 92/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0291 - accuracy: 0.9908 - val_loss: 0.0186 - val_accuracy: 0.9878\n",
            "Epoch 93/100\n",
            "33/33 [==============================] - 0s 6ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 0.0191 - val_accuracy: 0.9878\n",
            "Epoch 94/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.0198 - val_accuracy: 0.9878\n",
            "Epoch 95/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0286 - accuracy: 0.9908 - val_loss: 0.0197 - val_accuracy: 0.9878\n",
            "Epoch 96/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0278 - accuracy: 0.9938 - val_loss: 0.0206 - val_accuracy: 0.9878\n",
            "Epoch 97/100\n",
            "33/33 [==============================] - 0s 4ms/step - loss: 0.0276 - accuracy: 0.9908 - val_loss: 0.0213 - val_accuracy: 0.9878\n",
            "Epoch 98/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9908 - val_loss: 0.0218 - val_accuracy: 0.9878\n",
            "Epoch 99/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0266 - accuracy: 0.9908 - val_loss: 0.0213 - val_accuracy: 0.9878\n",
            "Epoch 100/100\n",
            "33/33 [==============================] - 0s 5ms/step - loss: 0.0260 - accuracy: 0.9969 - val_loss: 0.0215 - val_accuracy: 0.9878\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f67d2799c10>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Function to make predictions 1 or 0 by probs\n",
        "def binary_predictions(deepmodel, array_features):\n",
        "  prob_array = np.round(deepmodel.predict(array_features),2)\n",
        "  list_pred = []\n",
        "  for i in prob_array:\n",
        "    if i[0] > i[1]:\n",
        "      list_pred.append(0)\n",
        "    else:\n",
        "      list_pred.append(1)\n",
        "  return list_pred"
      ],
      "metadata": {
        "id": "ULa2GjTKVlOw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Predictions for the Test set\n",
        "y_pred = binary_predictions(model, X_test)\n",
        "#Make the y_test set unidimensional and binary again\n",
        "y_test_original = pd.DataFrame(y_test).idxmax(axis=1)"
      ],
      "metadata": {
        "id": "5sD5Cz-pV0Is"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confussion matrix for test set\n",
        "cm_hep = confusion_matrix(y_test_original, y_pred)\n",
        "ConfusionMatrixDisplay(cm_hep).plot()\n",
        "plt.grid(b=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "hS8TYXSGWF1v",
        "outputId": "3a114c4a-1643-4546-9f8e-1c1195cf889c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Classification report for test set data\n",
        "\n",
        "print(classification_report(y_test_original, y_pred, target_names=[\"Healthy\",\"Disease\"]))\n",
        "\n",
        "#>=.90 scores using all numerical features in f1-scores for all the classes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7E4NcvyWN-W",
        "outputId": "d18d16de-4d72-4761-f697-d778d0e381b8"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Healthy       0.99      1.00      0.99       158\n",
            "     Disease       1.00      0.88      0.94        17\n",
            "\n",
            "    accuracy                           0.99       175\n",
            "   macro avg       0.99      0.94      0.97       175\n",
            "weighted avg       0.99      0.99      0.99       175\n",
            "\n"
          ]
        }
      ]
    }
  ]
}